{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6b02923",
   "metadata": {},
   "source": [
    "# Extract Ground Truth Masks from Labelbox\n",
    "Sofware used for the video labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff104911",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/linus/Code/imu_processing/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "from extract_mask_from_video import *\n",
    "import labelbox as lb\n",
    "from utilities import *\n",
    "from imu_video_synch import get_participant_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ecf1ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API connection to Labelbox successful.\n"
     ]
    }
   ],
   "source": [
    "#CHANGE VALUES HERE #TODO\n",
    "participant_id = 'S001'\n",
    "# Labelbox API Connexion\n",
    "API_KEY = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VySWQiOiJjbHRvYTRhb2wwMGQxMDd6dDJ3eDQydHcyIiwib3JnYW5pemF0aW9uSWQiOiJjbHRvYTRhbzgwMGQwMDd6dGFidGo3cTU0IiwiYXBpS2V5SWQiOiJjbHc5MDAyM2owMGpkMDd6eTRnbjYxYjd0Iiwic2VjcmV0IjoiNDYxMTIyM2I5ZTYyOGIyM2M3ZmZlZjA0NzJiOTdmNzEiLCJpYXQiOjE3MTU4NDg2NzksImV4cCI6MjM0NzAwMDY3OX0.kTOUXuEjlpk8MQEmEnuy1E0NYnVHa30Sv73_F_Aoy70'\n",
    "project_key = 'clw8u6yxb02dk07yd2jqg4vgk'\n",
    "# Extract JSON data for the entire project ie all the participants \n",
    "export_json = extract_json_data(API_KEY, project_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4265145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Path: ../data/CreateStudy/S001/splitted_videos_LW\n"
     ]
    }
   ],
   "source": [
    "#PATH#\n",
    "initial_path = '../data/CreateStudy'\n",
    "subfolder_LW = 'splitted_videos_LW'\n",
    "screening_data = '../data/CreateStudy/screening_data_IMU_study.csv'\n",
    "# Left and Right Wrists\n",
    "side = ['LW', 'RW'] \n",
    "participant_path = os.path.join(initial_path, participant_id)\n",
    "video_path_LW = os.path.join(participant_path, subfolder_LW)\n",
    "print(\"Video Path:\", video_path_LW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f765792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get participant screening data\n",
    "participant_data = get_participant_info(participant_id, screening_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84f5c69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "# Get the number of videos for this participant \n",
    "# Can be adjust manually if files are not on the device anymore\n",
    "# Number of videos can be retrieve on Labelbox directly once uploaded \n",
    "number_videos = get_folder_element_count(video_path_LW)\n",
    "print(number_videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "453a29a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the video file paths \n",
    "videos_paths_LW, videos_paths_RW = get_all_video_path_participant_labelbox(participant_id, number_videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de64117e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Extract the GT Masks using the JSON file of the correct participant\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m GT_mask_LW \u001b[38;5;241m=\u001b[39m \u001b[43mextract_mask_from_videos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideos_paths_LW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexport_json\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m GT_mask_RW \u001b[38;5;241m=\u001b[39m extract_mask_from_videos(videos_paths_RW, export_json)\n",
      "File \u001b[0;32m~/Code/imu_processing/src/extract_mask_from_video.py:316\u001b[0m, in \u001b[0;36mextract_mask_from_videos\u001b[0;34m(videos_paths, export_json)\u001b[0m\n\u001b[1;32m    312\u001b[0m     segmented_data \u001b[38;5;241m=\u001b[39m segment_data(export_json, video_path)\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;66;03m# Extract the masks using the labeled frames\u001b[39;00m\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;66;03m#mask_video = get_mask(segmented_data)\u001b[39;00m\n\u001b[0;32m--> 316\u001b[0m     _, mask_video \u001b[38;5;241m=\u001b[39m \u001b[43mget_label_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43msegmented_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m     mask_per_video\u001b[38;5;241m.\u001b[39mappend(mask_video)\n\u001b[1;32m    319\u001b[0m \u001b[38;5;66;03m# Merge all the mask_video together using np.concatenate\u001b[39;00m\n",
      "File \u001b[0;32m~/Code/imu_processing/src/extract_mask_from_video.py:282\u001b[0m, in \u001b[0;36mget_label_mask\u001b[0;34m(segmented_data)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_label_mask\u001b[39m(segmented_data): \u001b[38;5;66;03m#replaces get_mask, parses JSON exported from labelbox\u001b[39;00m\n\u001b[1;32m    281\u001b[0m     project_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclw8u6yxb02dk07yd2jqg4vgk\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;66;03m#TODO\u001b[39;00m\n\u001b[0;32m--> 282\u001b[0m     labeled_frames \u001b[38;5;241m=\u001b[39m \u001b[43msegmented_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprojects\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[project_key][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mannotations\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mframes\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;66;03m#max_frame = max(labeled_frames.keys(), key=int) #get the maximum frame number maybe init lists here and fill at the exact frame position\u001b[39;00m\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;66;03m#functional_NF_frame_array, functional_NF_label_array = [-5] * max_frame, [-5] * max_frame\u001b[39;00m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m#functional_primitive_frame_array, primitive_label_array = [-5] * max_frame, [-5] * max_frame\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     functional_NF_frame_array, functional_NF_label_array \u001b[38;5;241m=\u001b[39m [], []\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "# Extract the GT Masks using the JSON file of the correct participant\n",
    "GT_mask_LW = extract_mask_from_videos(videos_paths_LW, export_json)\n",
    "GT_mask_RW = extract_mask_from_videos(videos_paths_RW, export_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4c9f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure dataset are balanced\n",
    "plot_movement_tendency(GT_mask_LW)\n",
    "plot_movement_tendency(GT_mask_RW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91759e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add masks to the participant dataset\n",
    "add_attributes_to_participant(participant_data, GT_mask_LW_25Hz = GT_mask_LW, GT_mask_RW_25Hz = GT_mask_RW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674a378d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the new data inside the json file associated to the participant \n",
    "save_to_json(participant_data, participant_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
