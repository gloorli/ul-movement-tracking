{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6b02923",
   "metadata": {},
   "source": [
    "# Extract Ground Truth Masks from Labelbox, sofware used for the video labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff104911",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pierre-Louis\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\Pierre-Louis\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.QVLO2T66WEPI7JZ63PS3HMOHFEY472BC.gfortran-win_amd64.dll\n",
      "C:\\Users\\Pierre-Louis\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "from extract_mask_from_video import *\n",
    "import labelbox as lb\n",
    "from utilities import *\n",
    "from imu_video_synch import get_participant_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ecf1ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHANGE VALUES HERE #TODO\n",
    "participant_id = 'H008'\n",
    "# Labelbox API Connexion\n",
    "API_KEY = ''\n",
    "project_key = ''\n",
    "# Extract JSON data for the entire project ie all the participants \n",
    "export_json = extract_json_data(API_KEY, project_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4265145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Path: ../CreateStudy\\H008\\splitted_videos_LW\n"
     ]
    }
   ],
   "source": [
    "#PATH#\n",
    "initial_path = '../CreateStudy'\n",
    "subfolder_LW = 'splitted_videos_LW'\n",
    "screening_data = '../CreateStudy/screening_data.csv'\n",
    "# Left and Right Wrists\n",
    "side = ['LW', 'RW'] \n",
    "participant_path = os.path.join(initial_path, participant_id)\n",
    "video_path_LW = os.path.join(participant_path, subfolder_LW)\n",
    "print(\"Video Path:\", video_path_LW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f765792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get participant screening data\n",
    "participant_data = get_participant_info(participant_id, screening_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84f5c69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "# Get the number of videos for this participant \n",
    "# Can be adjust manually if files are not on the device anymore\n",
    "# Number of videos can be retrieve on Labelbox directly once uploaded \n",
    "number_videos = get_folder_element_count(video_path_LW)\n",
    "print(number_videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "453a29a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the video file paths \n",
    "videos_paths_LW, videos_paths_RW = get_all_video_path_participant_labelbox(participant_id, number_videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de64117e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "max() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Extract the GT Masks using the JSON file of the correct participant\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m GT_mask_LW \u001b[38;5;241m=\u001b[39m \u001b[43mextract_mask_from_videos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideos_paths_LW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexport_json\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m GT_mask_RW \u001b[38;5;241m=\u001b[39m extract_mask_from_videos(videos_paths_RW, export_json)\n",
      "File \u001b[1;32m~\\Documents\\SEC\\ZurichMove\\extract_mask_from_video.py:274\u001b[0m, in \u001b[0;36mextract_mask_from_videos\u001b[1;34m(videos_paths, export_json)\u001b[0m\n\u001b[0;32m    271\u001b[0m     segmented_data \u001b[38;5;241m=\u001b[39m segment_data(export_json, video_path)\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;66;03m# Extract the masks using the labeled frames\u001b[39;00m\n\u001b[1;32m--> 274\u001b[0m     mask_video \u001b[38;5;241m=\u001b[39m \u001b[43mget_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43msegmented_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    275\u001b[0m     mask_per_video\u001b[38;5;241m.\u001b[39mappend(mask_video)\n\u001b[0;32m    277\u001b[0m \u001b[38;5;66;03m# Merge all the mask_video together using np.concatenate\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\SEC\\ZurichMove\\extract_mask_from_video.py:298\u001b[0m, in \u001b[0;36mget_mask\u001b[1;34m(segmented_data)\u001b[0m\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFrame and label arrays should have the same size.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    297\u001b[0m \u001b[38;5;66;03m# Prepare a mask array of the size of the maximum value contained inside frame_array\u001b[39;00m\n\u001b[1;32m--> 298\u001b[0m mask_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mframe_array\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    299\u001b[0m mask \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m5\u001b[39m] \u001b[38;5;241m*\u001b[39m mask_size\n\u001b[0;32m    301\u001b[0m \u001b[38;5;66;03m# Place the correct value of label at the correct frame position\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: max() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "# Extract the GT Masks using the JSON file of the correct participant\n",
    "GT_mask_LW = extract_mask_from_videos(videos_paths_LW, export_json)\n",
    "GT_mask_RW = extract_mask_from_videos(videos_paths_RW, export_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4c9f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure dataset are balanced\n",
    "plot_movement_tendency(GT_mask_LW)\n",
    "plot_movement_tendency(GT_mask_RW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91759e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add masks to the participant dataset\n",
    "add_attributes_to_participant(participant_data, GT_mask_LW_25Hz = GT_mask_LW, GT_mask_RW_25Hz = GT_mask_RW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674a378d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the new data inside the json file associated to the participant \n",
    "save_to_json(participant_data, participant_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
